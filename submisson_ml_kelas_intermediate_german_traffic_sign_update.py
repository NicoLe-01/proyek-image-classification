# -*- coding: utf-8 -*-
"""Submisson ML Kelas Intermediate German Traffic Sign Update.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hyKsq6ODpViOWhxWrGqmcJPxd9KPdLe5

Dataset : https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign
"""

import numpy as np
import pandas as pd
import os
import cv2
import matplotlib.pyplot as plt
import tensorflow as tf
import zipfile
from tensorflow import keras
from PIL import Image
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping

zip = '/content/drive/MyDrive/Dataset_Kaggle/German Traffic Sign Recognition Benchmark.zip'
unzip = zipfile.ZipFile(zip, 'r')
unzip.extractall('/content/dataset')
unzip.close()

data_dir = '/content/dataset'
train_dir = '/content/dataset/Train'
test_dir = '/content/dataset'

classes = { 0:'Speed limit (20km/h)',
            1:'Speed limit (30km/h)', 
            2:'Speed limit (50km/h)', 
            3:'Speed limit (60km/h)', 
            4:'Speed limit (70km/h)', 
            5:'Speed limit (80km/h)', 
            6:'End of speed limit (80km/h)', 
            7:'Speed limit (100km/h)', 
            8:'Speed limit (120km/h)', 
            9:'No passing', 
            10:'No passing veh over 3.5 tons', 
            11:'Right-of-way at intersection', 
            12:'Priority road', 
            13:'Yield', 
            14:'Stop', 
            15:'No vehicles', 
            16:'Veh > 3.5 tons prohibited', 
            17:'No entry', 
            18:'General caution', 
            19:'Dangerous curve left', 
            20:'Dangerous curve right', 
            21:'Double curve', 
            22:'Bumpy road', 
            23:'Slippery road', 
            24:'Road narrows on the right', 
            25:'Road work', 
            26:'Traffic signals', 
            27:'Pedestrians', 
            28:'Children crossing', 
            29:'Bicycles crossing', 
            30:'Beware of ice/snow',
            31:'Wild animals crossing', 
            32:'End speed + passing limits', 
            33:'Turn right ahead', 
            34:'Turn left ahead', 
            35:'Ahead only', 
            36:'Go straight or right', 
            37:'Go straight or left', 
            38:'Keep right', 
            39:'Keep left', 
            40:'Roundabout mandatory', 
            41:'End of no passing', 
            42:'End no passing veh > 3.5 tons' }

image_data = []
image_labels = []
for i in range(43):
    path = data_dir + '/Train/' + str(i)
    images = os.listdir(path)

    for img in images:
          image = cv2.imread(path + '/' + img)
          image_fromarray = Image.fromarray(image, 'RGB')
          resize_image = image_fromarray.resize((30, 30))
          image_data.append(np.array(resize_image))
          image_labels.append(i)

image_data = np.array(image_data)
image_labels = np.array(image_labels)

shuffle_indexes = np.arange(image_data.shape[0])
np.random.shuffle(shuffle_indexes)
image_data = image_data[shuffle_indexes]
image_labels = image_labels[shuffle_indexes]

img_train, img_test, label_train, label_test = train_test_split(image_data, image_labels, test_size=0.2, random_state=42, shuffle=True)

label_train = keras.utils.to_categorical(label_train, 43)
label_test = keras.utils.to_categorical(label_test, 43)

augmetation = ImageDataGenerator(rotation_range=10,
                                 zoom_range=0.15,
                                 shear_range=0.15,
                                 fill_mode='nearest')

model = keras.models.Sequential([    
    keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(30, 30, 3)),
    keras.layers.Conv2D(32, (3,3), activation='relu'),
    keras.layers.MaxPool2D((2, 2)),
    keras.layers.BatchNormalization(-1),
    keras.layers.Conv2D(64, (3,3), activation='relu'),
    keras.layers.Conv2D(128, (3,3), activation='relu'),
    keras.layers.MaxPool2D((2, 2)),
    keras.layers.BatchNormalization(-1),
    keras.layers.Flatten(),
    keras.layers.Dense(512, activation='relu'),
    keras.layers.BatchNormalization(),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(43, activation='softmax')
])

model.summary()

model.compile(optimizer='adam',
              loss=keras.losses.CategoricalCrossentropy(),
              metrics=['accuracy'])

early_stopping_monitor = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)

history = model.fit(augmetation.flow(img_train, label_train, batch_size=16), 
          epochs=30,
          validation_data = (img_test, label_test),
          batch_size=12,
          verbose=1,
          callbacks=[early_stopping_monitor])

accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

plt.plot(accuracy, 'b', label='Train accuracy')
plt.plot(val_accuracy, 'r', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()
plt.show()

plt.plot(loss, 'b', label='Train loss')
plt.plot(val_loss, 'r', label='Validation loss')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()
plt.show()

save_path = 'mymodel/'
tf.saved_model.save(model, save_path)

converter = tf.lite.TFLiteConverter.from_saved_model('/content/mymodel')
tflite_model = converter.convert()
 
with tf.io.gfile.GFile('German_trafic_sign.tflite', 'wb') as f:
    f.write(tflite_model)